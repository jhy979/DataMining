{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Cuda 혹은 cpu를 사용하시오.\n",
    "############Write Your Code Here############\n",
    "device = 'cuda'\n",
    "############################################\n",
    "\n",
    "\n",
    "#Custom_Dataset을 정의하시오.(10점)\n",
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        #입력으로 들어온 X의 pixel값들을 0-1사이로 normalize하고 X의 shape을 (FB,C,H,W)로 변경하여 저장하여 self.X,self.y에 저장하시오.\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        \n",
    "    def __len__(self):\n",
    "        #Custom_Dataset에 저장되어있는 총 data의 개수를 result에 저장하여 반환하시오.\n",
    "        result = 0\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        return result\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #self.X, self.y 에서 idx에 맞는 data를 result_X,result_y에 저장하여 반환하시오.\n",
    "        result_X,result_y = None,None\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        return result_X,result_y\n",
    "\n",
    "    \n",
    "#torch.nn을 사용하여 아래 함수들을 작성하시오. result는 nn.Layer중 하나이고 result를 반환함.(20점)\n",
    "def batch_norm(dim,for_MLP=True):\n",
    "    #for_MLP가 True일 시 MLP를 위한 BN Layer를 반환하고 False일 시 CNN을 위한 BN Layer를 반환함.\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def fc_layer(in_dim,out_dim):\n",
    "    #Fully Connected Layer(Dense Layer)\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def conv_layer(in_ch,out_ch,kernel_size, stride=1, padding=0):\n",
    "    #Convolutional Layer for image\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def relu():\n",
    "    #ReLU function\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "def flatten():\n",
    "    #Flatten the data\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    return result\n",
    "\n",
    "\n",
    "#skip_connection(bn -> relu -> conv -> bn -> relu -> conv)를 따르는 Res_block을 만드시오.\n",
    "#change_res가 True인 res_block을 통과한 feature map은 resolution이 2배 작아지고 channel의 깊이는 2배로 증가함. ex) 32*8*8 -> 64*4*4\n",
    "#위의 경우에는 skip_connection의 dimension은 1*1 conv로 맞춰줌.\n",
    "#change_res가 False인 Res_block을 통과한 feature map은 resolution과 channel의 깊이는 그대로 유지됨. ex) 32*4*4 -> 32*4*4(20점)\n",
    "class Res_block(nn.Module):\n",
    "    def __init__(self, input_channel, change_res):\n",
    "        super(Res_block,self).__init__()\n",
    "        self.change_res = change_res\n",
    "        if change_res:\n",
    "            ############Write Your Code Here############\n",
    "            \n",
    "            ############################################\n",
    "        else:\n",
    "            ############Write Your Code Here############\n",
    "            \n",
    "            ############################################\n",
    "        ############Write Your Code Here############\n",
    "            \n",
    "        ############################################\n",
    "    def forward(self,X):\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        return X\n",
    "\n",
    "    \n",
    "#Skip Connection을 이용하여 20개 이상의 layer를 가지고 테스트 셋에대하여 50% 이상의 성능을 주는 MLP를 만드시오.\n",
    "#nn.ModuleList를 사용하면 많을 층의 layer를 쌓는데 용이함.(20점)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP,self).__init__()\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "    def forward(self,X):\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        return X\n",
    "        \n",
    "#Res_Block을 사용하여 테스트 셋에대한 70% 이상의 성능을 주는 CNN 모델을 만드시오.\n",
    "#flatten전에 nn.AdaptiveAvgPool2d를 사용하면 dimension맞추기가 쉬움.(20점)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channel, class_number, block_number):\n",
    "        super(CNN,self).__init__()\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "    def forward(self,X):\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "        return X\n",
    "\n",
    "#loader에 있는 모든 data들에 대한 정확도를 구하여 accuracy에 저장하여 accuracy를 return하는 함수를 구현하시오.(10점)\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    accuracy = 0\n",
    "    total_example = 0\n",
    "    correct_example = 0\n",
    "    for data in loader:\n",
    "        x,y = data\n",
    "        x = torch.tensor(x, device = device)\n",
    "        y = torch.tensor(y, device = device)\n",
    "        ############Write Your Code Here############\n",
    "        \n",
    "        ############################################\n",
    "    ############Write Your Code Here############\n",
    "    \n",
    "    ############################################\n",
    "    model.train()\n",
    "    return accuracy\n",
    "\n",
    "#epoch마다 train_loader에 있는 batch들을 사용하여 모델을 학습하고\n",
    "#epoch의 마지막 iteration에서는 모델의 validation accuracy를 확인하여 제일 높은 val. acc.를 가진 model을 best_model에 저장하고\n",
    "#val_acc에는 매 epoch마다 구해진 validation accuracy를 저장하시오.\n",
    "#running_loss에는 각각의 epoch에서 모든 batch의 loss를 다 더하여 저장하시오.\n",
    "#모든 epoch의 validation accuracy를 val_acc에 저장하여 best_model과 val_acc를 return하는 함수를 구현하시오.(10점)\n",
    "def train(model, epoches, train_loader, val_loader, optimizer, criteria):\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    batch_len = len(train_loader)\n",
    "    val_acc = []\n",
    "    for epoch in range(epoches):\n",
    "        running_loss = 0\n",
    "        for i,data in enumerate(train_loader):\n",
    "            x,y = data\n",
    "            x = torch.tensor(x, device = device)\n",
    "            y = torch.tensor(y, device = device)\n",
    "            ############Write Your Code Here############\n",
    "            \n",
    "            ############################################\n",
    "            \n",
    "            #epoch의 마지막 iteration\n",
    "            if i % batch_len == batch_len-1:\n",
    "                print(f'{epoch+1}th iteration loss :',running_loss/batch_len)\n",
    "                running_loss = 0\n",
    "                ############Write Your Code Here############\n",
    "                \n",
    "                ############################################\n",
    "    return best_model, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(50점)\n",
    "#Read the data\n",
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True, download = True)\n",
    "testset = torchvision.datasets.CIFAR10(root = './data', train = False, download = True)\n",
    "\n",
    "X_train, Y_train = trainset.data, np.array(trainset.targets)\n",
    "X_test, Y_test = testset.data, np.array(testset.targets)\n",
    "\n",
    "\n",
    "#앞서 정의한 Custom_Dataset과 DataLoader를 사용하여 train_loader,val_loader,test_loader를 정의하시오.\n",
    "#Batch_size는 본인의 컴퓨터 사향에 맞게 변경하면 됨. Validation Set으로 Train Set의 20%를 사용함.\n",
    "#Preprocessing\n",
    "train_loader = None\n",
    "val_loader = None\n",
    "test_loader = None\n",
    "batch_size = 1\n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "#앞서 정의한 MLP,CNN을 사용하여 mlp_model,cnn_model을 정의하시오.\n",
    "#Define the model\n",
    "mlp_model = None\n",
    "cnn_model = None\n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "mlp_model.to(device)\n",
    "cnn_model.to(device)\n",
    "\n",
    "\n",
    "#앞서 정의한 train함수를 사용하여 best_mlp, mpl_val_acc, best_cnn, cnn_val_acc를 구하시오.\n",
    "#Train the model\n",
    "best_mlp = None\n",
    "mlp_val_acc = None\n",
    "best_cnn = None\n",
    "cnn_val_acc = None\n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "#앞서 정의한 evaluate함수와 best_model들을 사용하여 mlp_acc, cnn_acc를 구하시오.\n",
    "#Test Accuracy\n",
    "mlp_acc = None  \n",
    "cnn_acc = None \n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################\n",
    "print('MLP accuracy:',mlp_acc)\n",
    "print('CNN accuracy:',cnn_acc)\n",
    "\n",
    "\n",
    "#앞서 구한 val_acc들을 사용하여 이해 가능한 그래프를 그리시오.\n",
    "#Validation Accuracy Plot\n",
    "############Write Your Code Here############\n",
    "\n",
    "############################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
