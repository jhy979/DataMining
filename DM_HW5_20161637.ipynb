{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"name":"DM_Assignment_5.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Hi0HXI_9M8lY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622910559177,"user_tz":-540,"elapsed":2660,"user":{"displayName":"폰그만해","photoUrl":"","userId":"09232386909947476231"}},"outputId":"ad30b2c9-1318-4ac6-b9c7-636171a22140"},"source":["!pip install einops"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hc6X4fRDKP-j","executionInfo":{"status":"ok","timestamp":1622910559177,"user_tz":-540,"elapsed":4,"user":{"displayName":"폰그만해","photoUrl":"","userId":"09232386909947476231"}}},"source":["#구현하는 모델에서 쓰이는 모든 activation함수는 정의하여 드린 GELU 함수를 사용해야함.\n","#MultiHeadAttention에서 Head로 나눌때, 이미지를 patch로자른후 sequence로 만들때 Rearrange함수를 사용하면 편리함.(사용하지 않으셔도 됩니다)\n","#CIFAR10에 대한 test accuracy가 60프로 이상인 ViT모델을 만드시오.\n","import tensorflow as tf\n","from einops.layers.tensorflow import Rearrange\n","from tensorflow.keras.activations import gelu\n","GELU = lambda x : gelu(x)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"QrJci74oNV2m","executionInfo":{"status":"ok","timestamp":1622910559177,"user_tz":-540,"elapsed":3,"user":{"displayName":"폰그만해","photoUrl":"","userId":"09232386909947476231"}}},"source":["#논문[1]에서 설명하는 MultiHeadAttention을 만들어라.\n","class MultiHeadedAttention(tf.keras.Model):\n","    #dimension - 모델의 dimension(MHA를 거친 후의 dimension)\n","    def __init__(self, dimension, heads=8):\n","        super(MultiHeadedAttention, self).__init__()\n","        ############Write your code Here############\n","        self.heads = heads\n","        self.scale = dimension ** -0.5\n","        self.to_qkv = tf.keras.layers.Dense(dimension * 3, use_bias=False)\n","        self.to_out = tf.keras.layers.Dense(dimension)\n","\n","        self.rearrange_qkv = Rearrange('b n (qkv h d) -> qkv b h n d', qkv = 3, h = self.heads)\n","        self.rearrange_out = Rearrange('b h n d -> b n (h d)')\n","        ############################################\n","    def call(self, inputs):\n","        output = None\n","        ############Write your code Here############\n","        qkv = self.to_qkv(inputs)\n","        qkv = self.rearrange_qkv(qkv)\n","        q = qkv[0]\n","        k = qkv[1]\n","        v = qkv[2]\n","\n","        dots = tf.einsum('bhid,bhjd->bhij', q, k) * self.scale\n","        attn = tf.nn.softmax(dots,axis=-1)\n","\n","        output = tf.einsum('bhij,bhjd->bhid', attn, v)\n","        output = self.rearrange_out(output)\n","        output = self.to_out(output)\n","        ############################################\n","        return output\n"," \n","#인자로 받은 residual_function을 사용하여 real_function값을 return하여주는 Class를 만들어라.(call함수 참고)\n","class ResidualBlock(tf.keras.Model):\n","    def __init__(self, residual_function):\n","        super(ResidualBlock, self).__init__()\n","        ############Write your code Here############\n","        self.residual_function = residual_function\n","        ############################################\n"," \n","    def call(self, inputs):\n","        return self.residual_function(inputs) + inputs\n"," \n","#인자로 받은 normfunction에 들어가기전에 LayerNormalization을 해주는 Class를 만들어라.(call함수 참고)\n","class NormalizationBlock(tf.keras.Model):\n","    def __init__(self, norm_function, epsilon=1e-5):\n","        super(NormalizationBlock, self).__init__()\n","        ############Write your code Here############\n","        self.normalize = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n","        self.norm_function = norm_function\n","        ############################################\n"," \n","    def call(self, inputs):\n","        return self.norm_function(self.normalize(inputs))\n"," \n","#논문[1]에서의 MLPBlock을 만들어라.\n","class MLPBlock(tf.keras.Model):\n","    #output_dimension - MLPBlock의 output dimension\n","    #hidden_dimension - MLPBlock의 hidden layer dimension\n","    def __init__(self, output_dimension, hidden_dimension):\n","        super(MLPBlock, self).__init__()\n","        ############Write your code Here############\n","        self.net_fwd = tf.keras.Sequential()\n","        self.net_fwd.add(tf.keras.layers.Dense(hidden_dimension, activation=GELU)) \n","        self.net_fwd.add(tf.keras.layers.Dense(output_dimension))\n","        self.net_fwd.add(tf.keras.layers.Dropout(.2, input_shape=(output_dimension,)))\n","        ############################################\n"," \n","    def call(self, inputs):\n","        output = None\n","        ############Write your code Here############\n","        output=self.net_fwd(inputs)\n","        ############################################\n","        return output\n"," \n","#논문[1]을 읽고 TransformerEncoder를 위에서 정의한 class들을 사용하여 만들어라.\n","class TransformerEncoder(tf.keras.Model):\n","    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), heads - MHA에서 head의 개수\n","    #depth - encoder layer의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n","    def __init__(self, dimension, depth, heads, mlp_dimension): \n","        super(TransformerEncoder, self).__init__()\n","        layers_ = []\n","        for _ in range(depth):\n","            ############Write your code Here############\n","            layers_.extend([\n","                ResidualBlock(NormalizationBlock(MultiHeadedAttention(dimension, heads = heads))),\n","                ResidualBlock(NormalizationBlock(MLPBlock(dimension, mlp_dimension)))\n","            ])\n","            ############################################\n","        self.layers_ = tf.keras.Sequential(layers_)\n"," \n","    def call(self, inputs):\n","        return self.layers_(inputs)\n"," \n","#논문[2]를 읽고 ViT모델을 위에서 정의한 class들을 사용하여 만들어라.\n","class ImageTransformer(tf.keras.Model):\n","    #image_size - 이미지의 W==H의 크기(int), patch_size - 이미지를 쪼갤 patch의 크기(int)\n","    #n_classes - 최종 class의 개수, batch_size - 배치사이즈\n","    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), depth - encoder layer의 개수\n","    #heads - MHA에서 head의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n","    #channel - input image에 대한 channel의 수\n","    def __init__(\n","            self, image_size, patch_size, n_classes, batch_size,\n","            dimension, depth, heads, mlp_dimension, channels=3):\n","        super(ImageTransformer, self).__init__()\n","        assert image_size % patch_size == 0, 'invalid patch size for image size'\n"," \n","        num_patches = (image_size // patch_size) ** 2\n","        self.patch_size = patch_size\n","        self.dimension = dimension\n","        self.batch_size = batch_size\n","       \n","        self.positional_embedding = self.add_weight(\n","            \"position_embeddings\", shape=[num_patches + 1, dimension],\n","            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n","        )\n","        self.classification_token = self.add_weight(\n","            \"classification_token\", shape=[1, 1, dimension],\n","            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n","        )\n","        ############Write your code Here############\n","        self.patch_to_embedding = tf.keras.layers.Dense(dimension)\n","        self.rearrange = Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=self.patch_size, p2=self.patch_size)\n","        self.transformer = TransformerEncoder(dimension, depth, heads, mlp_dimension)\n","        self.identity = tf.identity\n","        self.mlp_head = tf.keras.Sequential([tf.keras.layers.Dense(mlp_dimension, activation=GELU), tf.keras.layers.Dense(n_classes)])\n","        ############################################\n"," \n","    def call(self, inputs):\n","        output = None\n","        ############Write your code Here############\n","        shapes = tf.shape(inputs)\n","\n","        x = self.rearrange(inputs)\n","        x = self.patch_to_embedding(x)\n","        \n","        classification_token = tf.broadcast_to(self.classification_token,(shapes[0],1,self.dimension))\n","        x = tf.concat((classification_token, x), axis=1)\n","        x += self.positional_embedding\n","        x = self.transformer(x)\n","\n","        x = self.identity(x[:, 0])\n","        output = self.mlp_head(x)\n","        ############################################\n","        return output"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAydwOELeFba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622911675464,"user_tz":-540,"elapsed":1116290,"user":{"displayName":"폰그만해","photoUrl":"","userId":"09232386909947476231"}},"outputId":"2327ab4b-0d0a-42e1-ce00-b4fccbb51283"},"source":["from tensorflow.keras import datasets\n","# Download and prepare the CIFAR10 dataset\n","(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","# Normalize pixel values to be between 0 and 1\n","############Write your code Here############\n","train_images = train_images /255\n","test_images = test_images /255\n","############################################\n","# Make image shape (BS, H, W, C) to (BS, C, H, W)\n","############Write your code Here############\n","import numpy as np\n","from tensorflow import keras\n","train_images= np.transpose(train_images,(0,3,1,2))\n","test_images= np.transpose(test_images,(0,3,1,2))\n","############################################\n","\n","#Initialize your model\n","#Initialize optimizer and loss and compile it to the model\n","############Write your code Here############\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","\n","image_size=32\n","patch_size=4\n","n_classes=10\n","batch_size=256\n","dimension=64\n","depth=10\n","heads=4\n","mlp_dimension=256\n","channels=3\n","\n","model =ImageTransformer(image_size,patch_size,n_classes,batch_size,dimension,depth,heads,mlp_dimension,channels)\n","model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","        ],\n","    )\n","############################################\n","\n","#Train your model\n","############Write your code Here############\n","model.fit(\n","        x=train_images,\n","        y=train_labels,\n","        batch_size=256,\n","        epochs=50,\n","        validation_split=0.2\n","    )\n","############################################\n","print('==============Training Finished===============')\n","\n","#Evaluate your test samples\n","accuracy = 0\n","############Write your code Here############\n","result = model.evaluate(test_images,test_labels,256)\n","accuracy=result[1]\n","############################################\n","\n","print('Test Accuracy :', accuracy)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","157/157 [==============================] - 34s 148ms/step - loss: 3.8168 - accuracy: 0.1231 - top-5-accuracy: 0.5453 - val_loss: 2.2051 - val_accuracy: 0.1605 - val_top-5-accuracy: 0.6589\n","Epoch 2/50\n","157/157 [==============================] - 22s 137ms/step - loss: 2.1262 - accuracy: 0.1866 - top-5-accuracy: 0.7088 - val_loss: 2.2412 - val_accuracy: 0.1654 - val_top-5-accuracy: 0.6726\n","Epoch 3/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.9752 - accuracy: 0.2552 - top-5-accuracy: 0.7883 - val_loss: 1.9540 - val_accuracy: 0.2783 - val_top-5-accuracy: 0.8037\n","Epoch 4/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.8199 - accuracy: 0.3244 - top-5-accuracy: 0.8399 - val_loss: 1.8317 - val_accuracy: 0.3331 - val_top-5-accuracy: 0.8459\n","Epoch 5/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.6973 - accuracy: 0.3711 - top-5-accuracy: 0.8747 - val_loss: 1.6512 - val_accuracy: 0.3938 - val_top-5-accuracy: 0.8822\n","Epoch 6/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.5802 - accuracy: 0.4212 - top-5-accuracy: 0.8962 - val_loss: 1.5553 - val_accuracy: 0.4243 - val_top-5-accuracy: 0.9045\n","Epoch 7/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.4909 - accuracy: 0.4570 - top-5-accuracy: 0.9111 - val_loss: 1.4480 - val_accuracy: 0.4655 - val_top-5-accuracy: 0.9166\n","Epoch 8/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.4274 - accuracy: 0.4820 - top-5-accuracy: 0.9211 - val_loss: 1.4058 - val_accuracy: 0.4889 - val_top-5-accuracy: 0.9207\n","Epoch 9/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.3859 - accuracy: 0.4968 - top-5-accuracy: 0.9260 - val_loss: 1.3948 - val_accuracy: 0.4936 - val_top-5-accuracy: 0.9267\n","Epoch 10/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.3345 - accuracy: 0.5184 - top-5-accuracy: 0.9329 - val_loss: 1.4098 - val_accuracy: 0.4997 - val_top-5-accuracy: 0.9208\n","Epoch 11/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.2981 - accuracy: 0.5350 - top-5-accuracy: 0.9380 - val_loss: 1.3290 - val_accuracy: 0.5120 - val_top-5-accuracy: 0.9346\n","Epoch 12/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.2495 - accuracy: 0.5501 - top-5-accuracy: 0.9449 - val_loss: 1.2385 - val_accuracy: 0.5613 - val_top-5-accuracy: 0.9426\n","Epoch 13/50\n","157/157 [==============================] - 21s 137ms/step - loss: 1.2112 - accuracy: 0.5625 - top-5-accuracy: 0.9483 - val_loss: 1.2905 - val_accuracy: 0.5499 - val_top-5-accuracy: 0.9396\n","Epoch 14/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.1868 - accuracy: 0.5747 - top-5-accuracy: 0.9532 - val_loss: 1.2637 - val_accuracy: 0.5430 - val_top-5-accuracy: 0.9426\n","Epoch 15/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.1536 - accuracy: 0.5868 - top-5-accuracy: 0.9543 - val_loss: 1.2695 - val_accuracy: 0.5542 - val_top-5-accuracy: 0.9374\n","Epoch 16/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.1151 - accuracy: 0.5996 - top-5-accuracy: 0.9567 - val_loss: 1.2229 - val_accuracy: 0.5661 - val_top-5-accuracy: 0.9466\n","Epoch 17/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.0936 - accuracy: 0.6094 - top-5-accuracy: 0.9602 - val_loss: 1.1734 - val_accuracy: 0.5885 - val_top-5-accuracy: 0.9510\n","Epoch 18/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.0533 - accuracy: 0.6227 - top-5-accuracy: 0.9644 - val_loss: 1.2102 - val_accuracy: 0.5783 - val_top-5-accuracy: 0.9473\n","Epoch 19/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.0346 - accuracy: 0.6329 - top-5-accuracy: 0.9648 - val_loss: 1.2115 - val_accuracy: 0.5894 - val_top-5-accuracy: 0.9502\n","Epoch 20/50\n","157/157 [==============================] - 21s 136ms/step - loss: 1.0131 - accuracy: 0.6421 - top-5-accuracy: 0.9667 - val_loss: 1.1684 - val_accuracy: 0.5995 - val_top-5-accuracy: 0.9528\n","Epoch 21/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.9949 - accuracy: 0.6438 - top-5-accuracy: 0.9679 - val_loss: 1.1276 - val_accuracy: 0.6061 - val_top-5-accuracy: 0.9570\n","Epoch 22/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.9779 - accuracy: 0.6523 - top-5-accuracy: 0.9700 - val_loss: 1.1868 - val_accuracy: 0.5899 - val_top-5-accuracy: 0.9522\n","Epoch 23/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.9518 - accuracy: 0.6623 - top-5-accuracy: 0.9710 - val_loss: 1.1630 - val_accuracy: 0.6036 - val_top-5-accuracy: 0.9506\n","Epoch 24/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.9355 - accuracy: 0.6697 - top-5-accuracy: 0.9713 - val_loss: 1.1934 - val_accuracy: 0.5963 - val_top-5-accuracy: 0.9500\n","Epoch 25/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.9138 - accuracy: 0.6777 - top-5-accuracy: 0.9730 - val_loss: 1.1295 - val_accuracy: 0.6086 - val_top-5-accuracy: 0.9538\n","Epoch 26/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.8898 - accuracy: 0.6853 - top-5-accuracy: 0.9754 - val_loss: 1.1583 - val_accuracy: 0.6051 - val_top-5-accuracy: 0.9562\n","Epoch 27/50\n","157/157 [==============================] - 21s 137ms/step - loss: 0.8863 - accuracy: 0.6854 - top-5-accuracy: 0.9761 - val_loss: 1.1198 - val_accuracy: 0.6131 - val_top-5-accuracy: 0.9546\n","Epoch 28/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.8595 - accuracy: 0.6945 - top-5-accuracy: 0.9765 - val_loss: 1.1285 - val_accuracy: 0.6119 - val_top-5-accuracy: 0.9543\n","Epoch 29/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.8475 - accuracy: 0.7030 - top-5-accuracy: 0.9770 - val_loss: 1.1399 - val_accuracy: 0.6133 - val_top-5-accuracy: 0.9523\n","Epoch 30/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.8417 - accuracy: 0.7019 - top-5-accuracy: 0.9775 - val_loss: 1.1763 - val_accuracy: 0.6143 - val_top-5-accuracy: 0.9547\n","Epoch 31/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.8123 - accuracy: 0.7137 - top-5-accuracy: 0.9799 - val_loss: 1.1614 - val_accuracy: 0.6169 - val_top-5-accuracy: 0.9576\n","Epoch 32/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.7928 - accuracy: 0.7221 - top-5-accuracy: 0.9801 - val_loss: 1.1790 - val_accuracy: 0.6167 - val_top-5-accuracy: 0.9536\n","Epoch 33/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.7943 - accuracy: 0.7222 - top-5-accuracy: 0.9798 - val_loss: 1.1175 - val_accuracy: 0.6255 - val_top-5-accuracy: 0.9546\n","Epoch 34/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.7511 - accuracy: 0.7324 - top-5-accuracy: 0.9829 - val_loss: 1.1500 - val_accuracy: 0.6228 - val_top-5-accuracy: 0.9564\n","Epoch 35/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.7481 - accuracy: 0.7363 - top-5-accuracy: 0.9822 - val_loss: 1.1695 - val_accuracy: 0.6201 - val_top-5-accuracy: 0.9575\n","Epoch 36/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.7375 - accuracy: 0.7407 - top-5-accuracy: 0.9826 - val_loss: 1.1828 - val_accuracy: 0.6233 - val_top-5-accuracy: 0.9505\n","Epoch 37/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.7190 - accuracy: 0.7477 - top-5-accuracy: 0.9838 - val_loss: 1.1746 - val_accuracy: 0.6181 - val_top-5-accuracy: 0.9524\n","Epoch 38/50\n","157/157 [==============================] - 21s 137ms/step - loss: 0.6897 - accuracy: 0.7562 - top-5-accuracy: 0.9851 - val_loss: 1.2911 - val_accuracy: 0.5963 - val_top-5-accuracy: 0.9515\n","Epoch 39/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.6831 - accuracy: 0.7601 - top-5-accuracy: 0.9849 - val_loss: 1.2498 - val_accuracy: 0.6130 - val_top-5-accuracy: 0.9485\n","Epoch 40/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.6764 - accuracy: 0.7620 - top-5-accuracy: 0.9856 - val_loss: 1.2142 - val_accuracy: 0.6374 - val_top-5-accuracy: 0.9550\n","Epoch 41/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.6643 - accuracy: 0.7696 - top-5-accuracy: 0.9847 - val_loss: 1.2132 - val_accuracy: 0.6247 - val_top-5-accuracy: 0.9548\n","Epoch 42/50\n","157/157 [==============================] - 21s 137ms/step - loss: 0.6473 - accuracy: 0.7744 - top-5-accuracy: 0.9862 - val_loss: 1.2792 - val_accuracy: 0.6217 - val_top-5-accuracy: 0.9494\n","Epoch 43/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.6288 - accuracy: 0.7808 - top-5-accuracy: 0.9865 - val_loss: 1.2128 - val_accuracy: 0.6317 - val_top-5-accuracy: 0.9542\n","Epoch 44/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.6043 - accuracy: 0.7904 - top-5-accuracy: 0.9870 - val_loss: 1.3136 - val_accuracy: 0.6195 - val_top-5-accuracy: 0.9502\n","Epoch 45/50\n","157/157 [==============================] - 21s 137ms/step - loss: 0.5924 - accuracy: 0.7967 - top-5-accuracy: 0.9876 - val_loss: 1.1694 - val_accuracy: 0.6318 - val_top-5-accuracy: 0.9537\n","Epoch 46/50\n","157/157 [==============================] - 21s 137ms/step - loss: 0.5829 - accuracy: 0.7957 - top-5-accuracy: 0.9886 - val_loss: 1.3026 - val_accuracy: 0.6214 - val_top-5-accuracy: 0.9511\n","Epoch 47/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.5626 - accuracy: 0.8046 - top-5-accuracy: 0.9890 - val_loss: 1.2478 - val_accuracy: 0.6242 - val_top-5-accuracy: 0.9539\n","Epoch 48/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.5306 - accuracy: 0.8160 - top-5-accuracy: 0.9900 - val_loss: 1.3167 - val_accuracy: 0.6300 - val_top-5-accuracy: 0.9482\n","Epoch 49/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.5152 - accuracy: 0.8206 - top-5-accuracy: 0.9907 - val_loss: 1.3330 - val_accuracy: 0.6133 - val_top-5-accuracy: 0.9441\n","Epoch 50/50\n","157/157 [==============================] - 21s 136ms/step - loss: 0.5259 - accuracy: 0.8183 - top-5-accuracy: 0.9897 - val_loss: 1.2975 - val_accuracy: 0.6228 - val_top-5-accuracy: 0.9474\n","==============Training Finished===============\n","40/40 [==============================] - 2s 53ms/step - loss: 1.2947 - accuracy: 0.6208 - top-5-accuracy: 0.9537\n","Test Accuracy : 0.6208000183105469\n"],"name":"stdout"}]}]}